# Interpretability Papers and Ideas

## Online book

https://christophm.github.io/interpretable-ml-book/

## Papers

Understanding Neural Networks Through Deep Visualization, ICML 2015

Visualizing deep neural network decisions: Prediction difference analysis, ICLR 2017

Modeling Latent Attention Within Neural Networks, ICLR 2018

(SHAP) A Unified Approach to Interpreting Model Predictions, NIPS 2017

Explainable machine-learning predictions for the prevention of hypoxaemia during surgery, Nature BME 2018

“ Why Should I Trust You ?” Explaining the Predictions of Any Classifier, KDD 2016

Anchors: High-Precision Model-Agnostic Explanations, AAAI 2018

Himabindu Lakkaraju, Stephen H Bach, and Jure Leskovec. Interpretable decision sets: A joint framework for description and prediction. In KDD, 2016

Learning to Explain: An Information-Theoretic Perspective on Model Interpretation, ICML 2018

(Rules based) Lakkaraju, H., Bach, S. H., & Leskovec, J. (2016). Interpretable decision sets: A joint framework for description and prediction. KDD
* 把数据集划分为相互独立的if-then集合
* https://github.com/lvhimabindu/interpretable_decision_sets

